{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "643cee07-8a11-4fd2-8b1e-ef7a08d4540c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mExecutionError\u001B[0m                            Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-4409814233663320>:1\u001B[0m\n",
       "\u001B[0;32m----> 1\u001B[0m \u001B[43mdbutils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmount\u001B[49m\u001B[43m(\u001B[49m\n",
       "\u001B[1;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[43msource\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mwasbs://srini-adlsgen2adventureworks@adlsgen2adventureworks.blob.core.windows.net/\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmount_point\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m/mnt/bronze-srini\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43mextra_configs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\n",
       "\u001B[1;32m      5\u001B[0m \u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mfs.azure.account.key.adlsgen2adventureworks.blob.core.windows.net\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mKFrirnuNDTcvixYNQIlGHiDoMLPrOeh5VvED866hfXh6Vn6OEFJXLGaSpHDTWzTp2ir503LwgUSu+ASt7YmK+w==\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\n",
       "\u001B[1;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43m}\u001B[49m\n",
       "\u001B[1;32m      7\u001B[0m \u001B[43m)\u001B[49m\n",
       "\n",
       "File \u001B[0;32m/databricks/python_shell/dbruntime/dbutils.py:362\u001B[0m, in \u001B[0;36mDBUtils.FSHandler.prettify_exception_message.<locals>.f_with_exception_handling\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m    360\u001B[0m exc\u001B[38;5;241m.\u001B[39m__context__ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
       "\u001B[1;32m    361\u001B[0m exc\u001B[38;5;241m.\u001B[39m__cause__ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
       "\u001B[0;32m--> 362\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m exc\n",
       "\n",
       "\u001B[0;31mExecutionError\u001B[0m: An error occurred while calling o398.mount.\n",
       ": java.rmi.RemoteException: java.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/bronze-srini; nested exception is: \n",
       "\tjava.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/bronze-srini\n",
       "\tat com.databricks.backend.daemon.data.client.DbfsClient.send0(DbfsClient.scala:135)\n",
       "\tat com.databricks.backend.daemon.data.client.DbfsClient.sendIdempotent(DbfsClient.scala:69)\n",
       "\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.createOrUpdateMount(DBUtilsCore.scala:1029)\n",
       "\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.$anonfun$mount$1(DBUtilsCore.scala:1055)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:560)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:656)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:677)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:414)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:158)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:412)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:409)\n",
       "\tat com.databricks.backend.daemon.dbutils.FSUtils.withAttributionContext(DBUtilsCore.scala:69)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:457)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:442)\n",
       "\tat com.databricks.backend.daemon.dbutils.FSUtils.withAttributionTags(DBUtilsCore.scala:69)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:651)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:569)\n",
       "\tat com.databricks.backend.daemon.dbutils.FSUtils.recordOperationWithResultTags(DBUtilsCore.scala:69)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:560)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:528)\n",
       "\tat com.databricks.backend.daemon.dbutils.FSUtils.recordOperation(DBUtilsCore.scala:69)\n",
       "\tat com.databricks.backend.daemon.dbutils.FSUtils.recordDbutilsFsOp(DBUtilsCore.scala:133)\n",
       "\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.mount(DBUtilsCore.scala:1049)\n",
       "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
       "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
       "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
       "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
       "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
       "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n",
       "\tat py4j.Gateway.invoke(Gateway.java:306)\n",
       "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
       "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
       "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:195)\n",
       "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:115)\n",
       "\tat java.lang.Thread.run(Thread.java:750)\n",
       "Caused by: java.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/bronze-srini\n",
       "\tat scala.Predef$.require(Predef.scala:281)\n",
       "\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.$anonfun$insertMount$1(MetadataManager.scala:692)\n",
       "\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.$anonfun$modifyAndVerify$2(MetadataManager.scala:1068)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.withRetries(MetadataManager.scala:841)\n",
       "\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.modifyAndVerify(MetadataManager.scala:1057)\n",
       "\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.insertMount(MetadataManager.scala:700)\n",
       "\tat com.databricks.backend.daemon.data.server.handler.MountHandler.receive(MountHandler.scala:128)\n",
       "\tat com.databricks.backend.daemon.data.server.handler.CEMountHandler.receive(MountHandler.scala:172)\n",
       "\tat com.databricks.backend.daemon.data.server.session.SessionContext.$anonfun$queryHandlers$1(SessionContext.scala:54)\n",
       "\tat com.databricks.backend.daemon.data.server.session.SessionContext.$anonfun$queryHandlers$1$adapted(SessionContext.scala:53)\n",
       "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
       "\tat com.databricks.backend.daemon.data.server.session.SessionContext.queryHandlers(SessionContext.scala:53)\n",
       "\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$4.$anonfun$applyOrElse$9(DbfsServerBackend.scala:387)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$4.applyOrElse(DbfsServerBackend.scala:387)\n",
       "\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$4.applyOrElse(DbfsServerBackend.scala:327)\n",
       "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:174)\n",
       "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n",
       "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n",
       "\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:171)\n",
       "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:147)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:573)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:676)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:694)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:671)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:582)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:573)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:542)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:22)\n",
       "\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:147)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:1021)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:942)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6(JettyServer.scala:546)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6$adapted(JettyServer.scala:515)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$4(ActivityContextFactory.scala:405)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:58)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$1(ActivityContextFactory.scala:405)\n",
       "\tat com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:75)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:380)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:159)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:515)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:405)\n",
       "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:665)\n",
       "\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)\n",
       "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:750)\n",
       "\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)\n",
       "\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)\n",
       "\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)\n",
       "\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)\n",
       "\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n",
       "\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n",
       "\tat org.eclipse.jetty.server.Server.handle(Server.java:516)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)\n",
       "\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\n",
       "\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\n",
       "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
       "\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)\n",
       "\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$4(InstrumentedQueuedThreadPool.scala:104)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:47)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:104)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:67)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:64)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:47)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:86)\n",
       "\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)\n",
       "\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)\n",
       "\tat java.lang.Thread.run(Thread.java:840)\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mExecutionError\u001B[0m                            Traceback (most recent call last)\nFile \u001B[0;32m<command-4409814233663320>:1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mdbutils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmount\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[43msource\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mwasbs://srini-adlsgen2adventureworks@adlsgen2adventureworks.blob.core.windows.net/\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmount_point\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m/mnt/bronze-srini\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43mextra_configs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mfs.azure.account.key.adlsgen2adventureworks.blob.core.windows.net\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mKFrirnuNDTcvixYNQIlGHiDoMLPrOeh5VvED866hfXh6Vn6OEFJXLGaSpHDTWzTp2ir503LwgUSu+ASt7YmK+w==\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\n\u001B[1;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43m}\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[43m)\u001B[49m\n\nFile \u001B[0;32m/databricks/python_shell/dbruntime/dbutils.py:362\u001B[0m, in \u001B[0;36mDBUtils.FSHandler.prettify_exception_message.<locals>.f_with_exception_handling\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    360\u001B[0m exc\u001B[38;5;241m.\u001B[39m__context__ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    361\u001B[0m exc\u001B[38;5;241m.\u001B[39m__cause__ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 362\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m exc\n\n\u001B[0;31mExecutionError\u001B[0m: An error occurred while calling o398.mount.\n: java.rmi.RemoteException: java.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/bronze-srini; nested exception is: \n\tjava.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/bronze-srini\n\tat com.databricks.backend.daemon.data.client.DbfsClient.send0(DbfsClient.scala:135)\n\tat com.databricks.backend.daemon.data.client.DbfsClient.sendIdempotent(DbfsClient.scala:69)\n\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.createOrUpdateMount(DBUtilsCore.scala:1029)\n\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.$anonfun$mount$1(DBUtilsCore.scala:1055)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:560)\n\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:656)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:677)\n\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:414)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:158)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:412)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:409)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.withAttributionContext(DBUtilsCore.scala:69)\n\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:457)\n\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:442)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.withAttributionTags(DBUtilsCore.scala:69)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:651)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:569)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.recordOperationWithResultTags(DBUtilsCore.scala:69)\n\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:560)\n\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:528)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.recordOperation(DBUtilsCore.scala:69)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.recordDbutilsFsOp(DBUtilsCore.scala:133)\n\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.mount(DBUtilsCore.scala:1049)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:306)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:195)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:115)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/bronze-srini\n\tat scala.Predef$.require(Predef.scala:281)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.$anonfun$insertMount$1(MetadataManager.scala:692)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.$anonfun$modifyAndVerify$2(MetadataManager.scala:1068)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.withRetries(MetadataManager.scala:841)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.modifyAndVerify(MetadataManager.scala:1057)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.insertMount(MetadataManager.scala:700)\n\tat com.databricks.backend.daemon.data.server.handler.MountHandler.receive(MountHandler.scala:128)\n\tat com.databricks.backend.daemon.data.server.handler.CEMountHandler.receive(MountHandler.scala:172)\n\tat com.databricks.backend.daemon.data.server.session.SessionContext.$anonfun$queryHandlers$1(SessionContext.scala:54)\n\tat com.databricks.backend.daemon.data.server.session.SessionContext.$anonfun$queryHandlers$1$adapted(SessionContext.scala:53)\n\tat scala.collection.immutable.List.foreach(List.scala:431)\n\tat com.databricks.backend.daemon.data.server.session.SessionContext.queryHandlers(SessionContext.scala:53)\n\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$4.$anonfun$applyOrElse$9(DbfsServerBackend.scala:387)\n\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)\n\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)\n\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$4.applyOrElse(DbfsServerBackend.scala:387)\n\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$4.applyOrElse(DbfsServerBackend.scala:327)\n\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:174)\n\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:171)\n\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:147)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:573)\n\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:676)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:694)\n\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)\n\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)\n\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:671)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:582)\n\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)\n\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:573)\n\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:542)\n\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:22)\n\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:147)\n\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:1021)\n\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:942)\n\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6(JettyServer.scala:546)\n\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6$adapted(JettyServer.scala:515)\n\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$4(ActivityContextFactory.scala:405)\n\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:58)\n\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$1(ActivityContextFactory.scala:405)\n\tat com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:75)\n\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:380)\n\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:159)\n\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:515)\n\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:405)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:665)\n\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:750)\n\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)\n\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)\n\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)\n\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)\n\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n\tat org.eclipse.jetty.server.Server.handle(Server.java:516)\n\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)\n\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)\n\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)\n\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\n\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\n\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\n\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)\n\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)\n\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)\n\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)\n\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)\n\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$4(InstrumentedQueuedThreadPool.scala:104)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n\tat com.databricks.rpc.InstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:47)\n\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:104)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:67)\n\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:64)\n\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:47)\n\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:86)\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)\n\tat java.lang.Thread.run(Thread.java:840)\n",
       "errorSummary": "java.rmi.RemoteException: java.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/bronze-srini; nested exception is: ",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "dbutils.fs.mount(\n",
    "    source='wasbs://srini-adlsgen2adventureworks@adlsgen2adventureworks.blob.core.windows.net/',\n",
    "    mount_point='/mnt/bronze-srini',\n",
    "    extra_configs={\n",
    "'fs.azure.account.key.adlsgen2adventureworks.blob.core.windows.net': 'KFrirnuNDTcvixYNQIlGHiDoMLPrOeh5VvED866hfXh6Vn6OEFJXLGaSpHDTWzTp2ir503LwgUSu+ASt7YmK+w=='\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7e4198cd-a015-4a9a-b89e-c116f52f9827",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "946f1970-4f61-40dd-9523-6661b5f27f35",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dbfs:/mnt/bronze-srini/BRONZE/HumanResources/Department/2024-02-21T10:59:31.7566414/HumanResources_Department.csv', 'dbfs:/mnt/bronze-srini/BRONZE/HumanResources/Employee/2024-02-21T10:59:51.2337011/HumanResources_Employee.csv', 'dbfs:/mnt/bronze-srini/BRONZE/HumanResources/EmployeeDepartmentHistory/2024-02-21T11:00:04.9490793/HumanResources_EmployeeDepartmentHistory.csv', 'dbfs:/mnt/bronze-srini/BRONZE/HumanResources/EmployeePayHistory/2024-02-21T11:00:19.5488464/HumanResources_EmployeePayHistory.csv', 'dbfs:/mnt/bronze-srini/BRONZE/HumanResources/JobCandidate/2024-02-21T11:00:35.0597455/HumanResources_JobCandidate.csv', 'dbfs:/mnt/bronze-srini/BRONZE/HumanResources/Shift/2024-02-21T11:00:52.2700202/HumanResources_Shift.csv', 'dbfs:/mnt/bronze-srini/BRONZE/Person/Address/2024-02-21T11:01:07.2385191/Person_Address.csv', 'dbfs:/mnt/bronze-srini/BRONZE/Person/AddressType/2024-02-21T11:01:37.4855778/Person_AddressType.csv', 'dbfs:/mnt/bronze-srini/BRONZE/Person/BusinessEntity/2024-02-21T11:01:47.6964553/Person_BusinessEntity.csv', 'dbfs:/mnt/bronze-srini/BRONZE/Person/BusinessEntityAddress/2024-02-21T11:02:05.9940375/Person_BusinessEntityAddress.csv', 'dbfs:/mnt/bronze-srini/BRONZE/Person/BusinessEntityContact/2024-02-21T11:02:31.9743910/Person_BusinessEntityContact.csv', 'dbfs:/mnt/bronze-srini/BRONZE/Person/ContactType/2024-02-21T11:02:48.2598925/Person_ContactType.csv', 'dbfs:/mnt/bronze-srini/BRONZE/Person/CountryRegion/2024-02-21T11:03:01.3756098/Person_CountryRegion.csv', 'dbfs:/mnt/bronze-srini/BRONZE/Person/EmailAddress/2024-02-21T11:03:18.2458663/Person_EmailAddress.csv', 'dbfs:/mnt/bronze-srini/BRONZE/Person/Password/2024-02-21T11:03:37.6045816/Person_Password.csv', 'dbfs:/mnt/bronze-srini/BRONZE/Person/Person/2024-02-21T11:03:52.8104955/Person_Person.csv', 'dbfs:/mnt/bronze-srini/BRONZE/Person/PersonPhone/2024-02-21T11:04:13.7069054/Person_PersonPhone.csv', 'dbfs:/mnt/bronze-srini/BRONZE/Person/PhoneNumberType/2024-02-21T11:04:32.7700065/Person_PhoneNumberType.csv', 'dbfs:/mnt/bronze-srini/BRONZE/Person/StateProvince/2024-02-21T11:04:47.8974871/Person_StateProvince.csv', 'dbfs:/mnt/bronze-srini/BRONZE/Production/BillOfMaterials/2024-02-21T11:05:04.1031169/Production_BillOfMaterials.csv', 'dbfs:/mnt/bronze-srini/BRONZE/Production/Culture/2024-02-21T11:05:20.7280619/Production_Culture.csv', 'dbfs:/mnt/bronze-srini/BRONZE/Production/Document/2024-02-21T11:05:36.4709323/Production_Document.csv', 'dbfs:/mnt/bronze-srini/BRONZE/Production/Illustration/2024-02-21T11:05:54.3219676/Production_Illustration.csv', 'dbfs:/mnt/bronze-srini/BRONZE/Production/Location/2024-02-21T11:06:09.6162211/Production_Location.csv', 'dbfs:/mnt/bronze-srini/BRONZE/Production/Product/2024-02-21T11:06:25.0123937/Production_Product.csv', 'dbfs:/mnt/bronze-srini/BRONZE/Production/ProductCategory/2024-02-21T11:06:42.6617387/Production_ProductCategory.csv', 'dbfs:/mnt/bronze-srini/BRONZE/Production/ProductCostHistory/2024-02-21T11:06:57.6890702/Production_ProductCostHistory.csv', 'dbfs:/mnt/bronze-srini/BRONZE/Production/ProductDescription/2024-02-21T11:07:17.4593772/Production_ProductDescription.csv', 'dbfs:/mnt/bronze-srini/BRONZE/Production/ProductDocument/2024-02-21T11:07:32.3048674/Production_ProductDocument.csv', 'dbfs:/mnt/bronze-srini/BRONZE/Production/ProductInventory/2024-02-21T11:07:48.2577114/Production_ProductInventory.csv', 'dbfs:/mnt/bronze-srini/BRONZE/Production/ProductListPriceHistory/2024-02-21T11:08:03.9901912/Production_ProductListPriceHistory.csv', 'dbfs:/mnt/bronze-srini/BRONZE/Production/ProductModel/2024-02-21T11:08:19.1889508/Production_ProductModel.csv', 'dbfs:/mnt/bronze-srini/BRONZE/Production/ProductModelIllustration/2024-02-21T11:08:35.8350600/Production_ProductModelIllustration.csv', 'dbfs:/mnt/bronze-srini/BRONZE/Production/ProductModelProductDescriptionCulture/2024-02-21T11:08:51.9765293/Production_ProductModelProductDescriptionCulture.csv', 'dbfs:/mnt/bronze-srini/BRONZE/Production/ProductPhoto/2024-02-21T11:09:08.6824932/Production_ProductPhoto.csv', 'dbfs:/mnt/bronze-srini/BRONZE/Production/ProductProductPhoto/2024-02-21T11:09:39.3618762/Production_ProductProductPhoto.csv', 'dbfs:/mnt/bronze-srini/BRONZE/Production/ProductReview/2024-02-21T11:09:57.0596199/Production_ProductReview.csv', 'dbfs:/mnt/bronze-srini/BRONZE/Production/ProductSubcategory/2024-02-21T11:10:13.2322333/Production_ProductSubcategory.csv', 'dbfs:/mnt/bronze-srini/BRONZE/Production/ScrapReason/2024-02-21T11:10:28.7384486/Production_ScrapReason.csv', 'dbfs:/mnt/bronze-srini/BRONZE/Production/TransactionHistory/2024-02-21T11:10:45.4207876/Production_TransactionHistory.csv', 'dbfs:/mnt/bronze-srini/BRONZE/Production/TransactionHistoryArchive/2024-02-21T11:11:42.7028255/Production_TransactionHistoryArchive.csv', 'dbfs:/mnt/bronze-srini/BRONZE/Production/UnitMeasure/2024-02-21T11:12:11.9484798/Production_UnitMeasure.csv', 'dbfs:/mnt/bronze-srini/BRONZE/Production/WorkOrder/2024-02-21T11:12:22.8939719/Production_WorkOrder.csv', 'dbfs:/mnt/bronze-srini/BRONZE/Production/WorkOrderRouting/2024-02-21T11:12:43.5631470/Production_WorkOrderRouting.csv', 'dbfs:/mnt/bronze-srini/BRONZE/Purchasing/ProductVendor/2024-02-21T11:13:20.9245237/Purchasing_ProductVendor.csv', 'dbfs:/mnt/bronze-srini/BRONZE/Purchasing/PurchaseOrderDetail/2024-02-21T11:13:36.5420888/Purchasing_PurchaseOrderDetail.csv', 'dbfs:/mnt/bronze-srini/BRONZE/Purchasing/PurchaseOrderHeader/2024-02-21T11:13:53.8031877/Purchasing_PurchaseOrderHeader.csv', 'dbfs:/mnt/bronze-srini/BRONZE/Purchasing/ShipMethod/2024-02-21T11:14:09.7996649/Purchasing_ShipMethod.csv', 'dbfs:/mnt/bronze-srini/BRONZE/Purchasing/Vendor/2024-02-21T11:14:24.4929151/Purchasing_Vendor.csv', 'dbfs:/mnt/bronze-srini/BRONZE/Sales/CountryRegionCurrency/2024-02-21T11:14:42.1172321/Sales_CountryRegionCurrency.csv', 'dbfs:/mnt/bronze-srini/BRONZE/Sales/CreditCard/2024-02-21T11:14:57.2604193/Sales_CreditCard.csv', 'dbfs:/mnt/bronze-srini/BRONZE/Sales/Currency/2024-02-21T11:15:15.0054200/Sales_Currency.csv', 'dbfs:/mnt/bronze-srini/BRONZE/Sales/CurrencyRate/2024-02-21T11:15:30.2650557/Sales_CurrencyRate.csv', 'dbfs:/mnt/bronze-srini/BRONZE/Sales/Customer/2024-02-21T11:15:52.3412300/Sales_Customer.csv', 'dbfs:/mnt/bronze-srini/BRONZE/Sales/PersonCreditCard/2024-02-21T11:16:10.5074751/Sales_PersonCreditCard.csv', 'dbfs:/mnt/bronze-srini/BRONZE/Sales/SalesOrderDetail/2024-02-21T11:16:30.8527940/Sales_SalesOrderDetail.csv', 'dbfs:/mnt/bronze-srini/BRONZE/Sales/SalesOrderHeader/2024-02-21T11:17:30.7047928/Sales_SalesOrderHeader.csv', 'dbfs:/mnt/bronze-srini/BRONZE/Sales/SalesOrderHeaderSalesReason/2024-02-21T11:18:12.0004982/Sales_SalesOrderHeaderSalesReason.csv', 'dbfs:/mnt/bronze-srini/BRONZE/Sales/SalesPerson/2024-02-21T11:18:33.1350495/Sales_SalesPerson.csv', 'dbfs:/mnt/bronze-srini/BRONZE/Sales/SalesPersonQuotaHistory/2024-02-21T11:18:45.9163888/Sales_SalesPersonQuotaHistory.csv', 'dbfs:/mnt/bronze-srini/BRONZE/Sales/SalesReason/2024-02-21T11:19:01.6107484/Sales_SalesReason.csv', 'dbfs:/mnt/bronze-srini/BRONZE/Sales/SalesTaxRate/2024-02-21T11:19:17.8936838/Sales_SalesTaxRate.csv', 'dbfs:/mnt/bronze-srini/BRONZE/Sales/SalesTerritory/2024-02-21T11:19:33.6686658/Sales_SalesTerritory.csv', 'dbfs:/mnt/bronze-srini/BRONZE/Sales/SalesTerritoryHistory/2024-02-21T11:19:50.5640979/Sales_SalesTerritoryHistory.csv', 'dbfs:/mnt/bronze-srini/BRONZE/Sales/ShoppingCartItem/2024-02-21T11:20:55.7633592/Sales_ShoppingCartItem.csv', 'dbfs:/mnt/bronze-srini/BRONZE/Sales/SpecialOffer/2024-02-21T11:21:11.4940958/Sales_SpecialOffer.csv', 'dbfs:/mnt/bronze-srini/BRONZE/Sales/SpecialOfferProduct/2024-02-21T11:21:28.0212743/Sales_SpecialOfferProduct.csv', 'dbfs:/mnt/bronze-srini/BRONZE/Sales/Store/2024-02-21T11:22:33.3176436/Sales_Store.csv', 'dbfs:/mnt/bronze-srini/BRONZE/dbo/AWBuildVersion/2024-02-21T10:58:46.4309999/dbo_AWBuildVersion.csv', 'dbfs:/mnt/bronze-srini/BRONZE/dbo/DatabaseLog/2024-02-21T10:58:59.6498098/dbo_DatabaseLog.csv', 'dbfs:/mnt/bronze-srini/BRONZE/dbo/ErrorLog/2024-02-21T10:59:19.4827471/dbo_ErrorLog.csv']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "PD_PATH = \"/mnt/bronze-srini/BRONZE\"\n",
    "\n",
    "def list_files_recursively(directory):\n",
    "    file_paths = []\n",
    "   \n",
    "    files = dbutils.fs.ls(directory)\n",
    "    for file in files:\n",
    "        if file.isDir():\n",
    "            # If the item is a directory, recursively call the function\n",
    "            file_paths.extend(list_files_recursively(file.path))\n",
    "        else:\n",
    "            # If the item is a file, append its path to the list\n",
    "            file_paths.append(file.path)\n",
    "    return file_paths\n",
    " \n",
    "# Get list of all files in the parent directory and its subdirectories\n",
    "file_paths = list_files_recursively(PD_PATH )\n",
    "print(file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cfd7331a-ea9d-4a82-ac74-2e2b56c2b68f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[DepartmentID: int, Name: string, GroupName: string, ModifiedDate: timestamp]\nDataFrame[BusinessEntityID: int, NationalIDNumber: int, LoginID: string, OrganizationNode: string, OrganizationLevel: int, JobTitle: string, BirthDate: timestamp, MaritalStatus: string, Gender: string, HireDate: timestamp, SalariedFlag: boolean, VacationHours: int, SickLeaveHours: int, CurrentFlag: boolean, rowguid: string, ModifiedDate: timestamp]\nDataFrame[BusinessEntityID: int, DepartmentID: int, ShiftID: int, StartDate: timestamp, EndDate: timestamp, ModifiedDate: timestamp]\nDataFrame[BusinessEntityID: int, RateChangeDate: timestamp, Rate: double, PayFrequency: int, ModifiedDate: timestamp]\nDataFrame[JobCandidateID: string, BusinessEntityID: string, Resume: string, ModifiedDate: string]\nDataFrame[ShiftID: int, Name: string, StartTime: timestamp, EndTime: timestamp, ModifiedDate: timestamp]\nDataFrame[AddressID: int, AddressLine1: string, AddressLine2: string, City: string, StateProvinceID: int, PostalCode: string, SpatialLocation: string, rowguid: string, ModifiedDate: timestamp]\nDataFrame[AddressTypeID: int, Name: string, rowguid: string, ModifiedDate: timestamp]\nDataFrame[BusinessEntityID: int, rowguid: string, ModifiedDate: timestamp]\nDataFrame[BusinessEntityID: int, AddressID: int, AddressTypeID: int, rowguid: string, ModifiedDate: timestamp]\nDataFrame[BusinessEntityID: int, PersonID: int, ContactTypeID: int, rowguid: string, ModifiedDate: timestamp]\nDataFrame[ContactTypeID: int, Name: string, ModifiedDate: timestamp]\nDataFrame[CountryRegionCode: string, Name: string, ModifiedDate: timestamp]\nDataFrame[BusinessEntityID: int, EmailAddressID: int, EmailAddress: string, rowguid: string, ModifiedDate: timestamp]\nDataFrame[BusinessEntityID: int, PasswordHash: string, PasswordSalt: string, rowguid: string, ModifiedDate: timestamp]\nDataFrame[BusinessEntityID: int, PersonType: string, NameStyle: boolean, Title: string, FirstName: string, MiddleName: string, LastName: string, Suffix: string, EmailPromotion: int, AdditionalContactInfo: string, Demographics: string, rowguid: string, ModifiedDate: timestamp]\nDataFrame[BusinessEntityID: int, PhoneNumber: string, PhoneNumberTypeID: int, ModifiedDate: timestamp]\nDataFrame[PhoneNumberTypeID: int, Name: string, ModifiedDate: timestamp]\nDataFrame[StateProvinceID: int, StateProvinceCode: string, CountryRegionCode: string, IsOnlyStateProvinceFlag: boolean, Name: string, TerritoryID: int, rowguid: string, ModifiedDate: timestamp]\nDataFrame[BillOfMaterialsID: int, ProductAssemblyID: int, ComponentID: int, StartDate: timestamp, EndDate: timestamp, UnitMeasureCode: string, BOMLevel: int, PerAssemblyQty: double, ModifiedDate: timestamp]\nDataFrame[CultureID: string, Name: string, ModifiedDate: timestamp]\nDataFrame[DocumentNode: string, DocumentLevel: int, Title: string, Owner: int, FolderFlag: boolean, FileName: string, FileExtension: string, Revision: double, ChangeNumber: int, Status: int, DocumentSummary: string, Document: string, rowguid: string, ModifiedDate: timestamp]\nDataFrame[IllustrationID: int, Diagram: string, ModifiedDate: timestamp]\nDataFrame[LocationID: int, Name: string, CostRate: double, Availability: double, ModifiedDate: timestamp]\nDataFrame[ProductID: int, Name: string, ProductNumber: string, MakeFlag: boolean, FinishedGoodsFlag: boolean, Color: string, SafetyStockLevel: int, ReorderPoint: int, StandardCost: double, ListPrice: double, Size: string, SizeUnitMeasureCode: string, WeightUnitMeasureCode: string, Weight: double, DaysToManufacture: int, ProductLine: string, Class: string, Style: string, ProductSubcategoryID: int, ProductModelID: int, SellStartDate: timestamp, SellEndDate: timestamp, DiscontinuedDate: string, rowguid: string, ModifiedDate: timestamp]\nDataFrame[ProductCategoryID: int, Name: string, rowguid: string, ModifiedDate: timestamp]\nDataFrame[ProductID: int, StartDate: timestamp, EndDate: timestamp, StandardCost: double, ModifiedDate: timestamp]\nDataFrame[ProductDescriptionID: int, Description: string, rowguid: string, ModifiedDate: timestamp]\nDataFrame[ProductID: int, DocumentNode: string, ModifiedDate: timestamp]\nDataFrame[ProductID: int, LocationID: int, Shelf: string, Bin: int, Quantity: int, rowguid: string, ModifiedDate: timestamp]\nDataFrame[ProductID: int, StartDate: timestamp, EndDate: timestamp, ListPrice: double, ModifiedDate: timestamp]\nDataFrame[ProductModelID: string, Name: string, CatalogDescription: string, Instructions: string, rowguid: string, ModifiedDate: timestamp]\nDataFrame[ProductModelID: int, IllustrationID: int, ModifiedDate: timestamp]\nDataFrame[ProductModelID: int, ProductDescriptionID: int, CultureID: string, ModifiedDate: timestamp]\nDataFrame[ProductPhotoID: int, ThumbNailPhoto: string, ThumbnailPhotoFileName: string, LargePhoto: string, LargePhotoFileName: string, ModifiedDate: timestamp]\nDataFrame[ProductID: int, ProductPhotoID: int, Primary: boolean, ModifiedDate: timestamp]\nDataFrame[ProductReviewID: string, ProductID: string, ReviewerName: string, ReviewDate: string, EmailAddress: string, Rating: int, Comments: string, ModifiedDate: string]\nDataFrame[ProductSubcategoryID: int, ProductCategoryID: int, Name: string, rowguid: string, ModifiedDate: timestamp]\nDataFrame[ScrapReasonID: int, Name: string, ModifiedDate: timestamp]\nDataFrame[TransactionID: int, ProductID: int, ReferenceOrderID: int, ReferenceOrderLineID: int, TransactionDate: timestamp, TransactionType: string, Quantity: int, ActualCost: double, ModifiedDate: timestamp]\nDataFrame[TransactionID: int, ProductID: int, ReferenceOrderID: int, ReferenceOrderLineID: int, TransactionDate: timestamp, TransactionType: string, Quantity: int, ActualCost: double, ModifiedDate: timestamp]\nDataFrame[UnitMeasureCode: string, Name: string, ModifiedDate: timestamp]\nDataFrame[WorkOrderID: int, ProductID: int, OrderQty: int, StockedQty: int, ScrappedQty: int, StartDate: timestamp, EndDate: timestamp, DueDate: timestamp, ScrapReasonID: int, ModifiedDate: timestamp]\nDataFrame[WorkOrderID: int, ProductID: int, OperationSequence: int, LocationID: int, ScheduledStartDate: timestamp, ScheduledEndDate: timestamp, ActualStartDate: timestamp, ActualEndDate: timestamp, ActualResourceHrs: double, PlannedCost: double, ActualCost: double, ModifiedDate: timestamp]\nDataFrame[ProductID: int, BusinessEntityID: int, AverageLeadTime: int, StandardPrice: double, LastReceiptCost: double, LastReceiptDate: timestamp, MinOrderQty: int, MaxOrderQty: int, OnOrderQty: int, UnitMeasureCode: string, ModifiedDate: timestamp]\nDataFrame[PurchaseOrderID: int, PurchaseOrderDetailID: int, DueDate: timestamp, OrderQty: int, ProductID: int, UnitPrice: double, LineTotal: double, ReceivedQty: double, RejectedQty: double, StockedQty: double, ModifiedDate: timestamp]\nDataFrame[PurchaseOrderID: int, RevisionNumber: int, Status: int, EmployeeID: int, VendorID: int, ShipMethodID: int, OrderDate: timestamp, ShipDate: timestamp, SubTotal: double, TaxAmt: double, Freight: double, TotalDue: double, ModifiedDate: timestamp]\nDataFrame[ShipMethodID: int, Name: string, ShipBase: double, ShipRate: double, rowguid: string, ModifiedDate: timestamp]\nDataFrame[BusinessEntityID: int, AccountNumber: string, Name: string, CreditRating: int, PreferredVendorStatus: boolean, ActiveFlag: boolean, PurchasingWebServiceURL: string, ModifiedDate: timestamp]\nDataFrame[CountryRegionCode: string, CurrencyCode: string, ModifiedDate: timestamp]\nDataFrame[CreditCardID: int, CardType: string, CardNumber: bigint, ExpMonth: int, ExpYear: int, ModifiedDate: timestamp]\nDataFrame[CurrencyCode: string, Name: string, ModifiedDate: timestamp]\nDataFrame[CurrencyRateID: int, CurrencyRateDate: timestamp, FromCurrencyCode: string, ToCurrencyCode: string, AverageRate: double, EndOfDayRate: double, ModifiedDate: timestamp]\nDataFrame[CustomerID: int, PersonID: int, StoreID: int, TerritoryID: int, AccountNumber: string, rowguid: string, ModifiedDate: timestamp]\nDataFrame[BusinessEntityID: int, CreditCardID: int, ModifiedDate: timestamp]\nDataFrame[SalesOrderID: int, SalesOrderDetailID: int, CarrierTrackingNumber: string, OrderQty: int, ProductID: int, SpecialOfferID: int, UnitPrice: double, UnitPriceDiscount: double, LineTotal: double, rowguid: string, ModifiedDate: timestamp]\nDataFrame[SalesOrderID: int, RevisionNumber: int, OrderDate: timestamp, DueDate: timestamp, ShipDate: timestamp, Status: int, OnlineOrderFlag: boolean, SalesOrderNumber: string, PurchaseOrderNumber: string, AccountNumber: string, CustomerID: int, SalesPersonID: int, TerritoryID: int, BillToAddressID: int, ShipToAddressID: int, ShipMethodID: int, CreditCardID: int, CreditCardApprovalCode: string, CurrencyRateID: int, SubTotal: double, TaxAmt: double, Freight: double, TotalDue: double, Comment: string, rowguid: string, ModifiedDate: timestamp]\nDataFrame[SalesOrderID: int, SalesReasonID: int, ModifiedDate: timestamp]\nDataFrame[BusinessEntityID: int, TerritoryID: int, SalesQuota: double, Bonus: double, CommissionPct: double, SalesYTD: double, SalesLastYear: double, rowguid: string, ModifiedDate: timestamp]\nDataFrame[BusinessEntityID: int, QuotaDate: timestamp, SalesQuota: double, rowguid: string, ModifiedDate: timestamp]\nDataFrame[SalesReasonID: int, Name: string, ReasonType: string, ModifiedDate: timestamp]\nDataFrame[SalesTaxRateID: int, StateProvinceID: int, TaxType: int, TaxRate: double, Name: string, rowguid: string, ModifiedDate: timestamp]\nDataFrame[TerritoryID: int, Name: string, CountryRegionCode: string, Group: string, SalesYTD: double, SalesLastYear: double, CostYTD: double, CostLastYear: double, rowguid: string, ModifiedDate: timestamp]\nDataFrame[BusinessEntityID: int, TerritoryID: int, StartDate: timestamp, EndDate: timestamp, rowguid: string, ModifiedDate: timestamp]\nDataFrame[ShoppingCartItemID: int, ShoppingCartID: int, Quantity: int, ProductID: int, DateCreated: timestamp, ModifiedDate: timestamp]\nDataFrame[SpecialOfferID: int, Description: string, DiscountPct: double, Type: string, Category: string, StartDate: timestamp, EndDate: timestamp, MinQty: int, MaxQty: int, rowguid: string, ModifiedDate: timestamp]\nDataFrame[SpecialOfferID: int, ProductID: int, rowguid: string, ModifiedDate: timestamp]\nDataFrame[BusinessEntityID: int, Name: string, SalesPersonID: int, Demographics: string, rowguid: string, ModifiedDate: timestamp]\nDataFrame[SystemInformationID: int, Database Version: string, VersionDate: timestamp, ModifiedDate: timestamp]\nDataFrame[DatabaseLogID: string, PostTime: string, DatabaseUser: string, Event: string, Schema: string, Object: string, TSQL: string, XmlEvent: string]\nDataFrame[ErrorLogID: string, ErrorTime: string, UserName: string, ErrorNumber: string, ErrorSeverity: string, ErrorState: string, ErrorProcedure: string, ErrorLine: string, ErrorMessage: string]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "import datetime as dt\n",
    "from datetime import datetime \n",
    "import datetime,pytz\n",
    "from pyspark.sql.functions import substring, col, lit, concat, expr\n",
    "for file in file_paths:\n",
    "\n",
    "    df = spark.read.csv(file, header=True, inferSchema=True)\n",
    "    print(df)\n",
    "    for column in df.columns:\n",
    "        \n",
    "        def encode_to_utf8(text):     \n",
    "         return text.encode('utf-8') \n",
    "         df=df.withColumn(column,encode_to_utf8(column))\n",
    "        if df.schema[column].dataType == StringType():\n",
    "            df = df.withColumn(column,upper(df[column]))\n",
    "        if df.schema[column].dataType == DecimalType() or df.schema[column].dataType == DoubleType():\n",
    "            df.withColumn(column, format_number(df[column],2))\n",
    "        if column == 'AverageRate' or column == 'EndOfDayRate':\n",
    "            df.withColumn(column, floor(df[column]*75))\n",
    "        fp= 'dbfs:/mnt/bronze-srini/BRONZE/Production/Product/2024-02-21T11:03:01.3756098/Production_Product.csv'\n",
    "        if file ==fp:\n",
    "            df = spark.read.csv(file, header=True, inferSchema=True)  \n",
    "        if column == 'ProductNumber':\n",
    "            df = df.withColumn('ProductNumber', concat(col('Name'), substring(col('ProductNumber'), 3, 100)))\n",
    "\n",
    "        f_p= 'dbfs:/mnt/bronze-srini/BRONZE/Person/CountryRegion/2024-02-21T11:03:01.3756098/Person_CountryRegion.csv'  \n",
    "        if file ==f_p:\n",
    "            df = spark.read.csv(file, header=True, inferSchema=True)\n",
    "        if column == 'Name':   \n",
    "            df=df.withColumn('New_Region_Name', upper(substring('Name', 1,3)))\n",
    "               # df.show()\n",
    "    \n",
    "    current_timestamp = datetime.datetime.now(pytz.timezone('Asia/Kolkata')).strftime('%Y-%m-%dT%H-%M-%S.%f')[:-3]\n",
    " \n",
    "      # Split the file_path string based on '/'\n",
    "    path_parts = file.split('/')\n",
    " \n",
    "     # Replace 'Bronze' with 'Silver' in the path_parts list\n",
    "    path_parts[path_parts.index('BRONZE')] = 'Silver'\n",
    " \n",
    "     # Replace the timestamp part with the current timestamp\n",
    "    path_parts[-2] = current_timestamp\n",
    " \n",
    "     # Join the path_parts list back into a string using '/'\n",
    "    dynamic_path = '/'.join(path_parts)\n",
    "    df.write.csv(dynamic_path,header=True, mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fd38258a-0587-4efc-9c96-040c16a425e6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#f_p= 'dbfs:/mnt/bronze-srini/BRONZE/Person/CountryRegion/2024-02-21T11:03:01.3756098/Person_CountryRegion.csv'  \n",
    "        #if file ==f_p:\n",
    "           # df = spark.read.csv(file, header=True, inferSchema=True)\n",
    "           # if column == 'Name':   \n",
    "                #df=df.withColumn('New_Region_Name', upper(substring('Name', 1,3)))\n",
    "               # df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1754186-731c-4bc5-a391-ac9894f14a8b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dbfs:/mnt/bronze-srini/Silver/Person/CountryRegion/2024-02-29 13:43:36.694178+05:30/Person_CountryRegion.csv\n"
     ]
    }
   ],
   "source": [
    "import datetime,pytz\n",
    " \n",
    "file_path = 'dbfs:/mnt/bronze-srini/BRONZE/Person/CountryRegion/2024-02-21T11:03:01.3756098/Person_CountryRegion.csv'\n",
    "  \n",
    "# Get the current timestamp\n",
    "current_timestamp = str(datetime.datetime.now(pytz.timezone('Asia/Kolkata')))#strftime('%Y-%m-%dT%H:%M:%S.%f')[:-3]\n",
    " \n",
    "# Split the file_path string based on '/'\n",
    "path_parts = file.split('/')\n",
    " \n",
    "# Replace 'Bronze' with 'Silver' in the path_parts list\n",
    "path_parts[path_parts.index('BRONZE')] = 'Silver'\n",
    " \n",
    "# Replace the timestamp part with the current timestamp\n",
    "path_parts[-2] = current_timestamp\n",
    " \n",
    "# Join the path_parts list back into a string using '/'\n",
    "dynamic_path = '/'.join(path_parts)\n",
    " \n",
    "print(dynamic_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "33990aac-31f7-474c-a738-280ff916fc7a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-29 11:34:12.485183+05:30\n"
     ]
    }
   ],
   "source": [
    "current_timestamp = str(datetime.datetime.now(pytz.timezone('Asia/Kolkata'))) #strftime('%Y-%m-%dT%H:%M:%S.%f')[:-3]\n",
    "print(current_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bf5efc60-5df0-4889-aa4f-6979f5d9a8f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-29 09:12:59.237637+00:00\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "\n",
    "\n",
    "\n",
    "dt_UTC_aware = dt.datetime.now(dt.timezone.utc)\n",
    "print(dt_UTC_aware)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b6521c2-6393-4a9b-ba7a-779341d49f64",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-1221095670704161>:1\u001B[0m\n",
       "\u001B[0;32m----> 1\u001B[0m timestamp \u001B[38;5;241m=\u001B[39m \u001B[43mdatetime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnow\u001B[49m(pytz\u001B[38;5;241m.\u001B[39mtimezone(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAsia/Kolkata\u001B[39m\u001B[38;5;124m'\u001B[39m))\n",
       "\n",
       "\u001B[0;31mAttributeError\u001B[0m: module 'datetime' has no attribute 'now'"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)\nFile \u001B[0;32m<command-1221095670704161>:1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m timestamp \u001B[38;5;241m=\u001B[39m \u001B[43mdatetime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnow\u001B[49m(pytz\u001B[38;5;241m.\u001B[39mtimezone(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAsia/Kolkata\u001B[39m\u001B[38;5;124m'\u001B[39m))\n\n\u001B[0;31mAttributeError\u001B[0m: module 'datetime' has no attribute 'now'",
       "errorSummary": "<span class='ansi-red-fg'>AttributeError</span>: module 'datetime' has no attribute 'now'",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "timestamp = datetime.now(pytz.timezone('Asia/Kolkata'))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "07c4673e-651e-429f-9647-eb32b95e3a82",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def encode_to_utf8(text):     \n",
    "    return text.encode('utf-8') \n",
    "    udf = udf(encode_to_utf8, StringType()) # Apply the UDF to the DataFrame \n",
    "columndf_encoded = df.withColumn(\"encoded_text\", encode_udf(df[\"text\"]))\n",
    " df=df.withColumn('encode_to_utf8', StringType())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d708bbd1-01de-4e35-97b2-42ef718f4216",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df=df.write.csv(dynamic_path,header=True,mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cd5928cb-6727-4b14-8314-fd4e3145af38",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_upper = df.withColumn(\"text_field_upper\", upper(col(\"text_field\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cf2321b9-5252-4f37-a703-1f273e8af25a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Format numeric_field to a consistent number of decimal places\n",
    "df_formatted = df.withColumn(\"formatted_numeric_field\", format(col(\"numeric_field\"),2))\n",
    "\n",
    "# Show the resulting DataFrame\n",
    "df_formatted.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "10a13e64-123a-4d30-9af5-28a8a026d171",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define a mapping dictionary for abbreviation expansion\n",
    "abbreviations_map = {\n",
    "    \"Dr.\": \"Doctor\",\n",
    "    \"Mr.\": \"Mister\",\n",
    "    \"Mrs.\": \"Missus\",\n",
    "    # Add more abbreviations and their expanded forms as needed\n",
    "}\n",
    "\n",
    "# Create a function to expand abbreviations\n",
    "def expand_abbreviations(text):\n",
    "    for abbreviation, expansion in abbreviations_map.items():\n",
    "        text = text.replace(abbreviation, expansion)\n",
    "    return text\n",
    "\n",
    "# Register the UDF\n",
    "expand_abbreviations_udf = spark.udf.register(\"expand_abbreviations\", expand_abbreviations)\n",
    "\n",
    "# Apply the UDF to expand abbreviations\n",
    "df_expanded = df.withColumn(\"expanded_text\", expand_abbreviations_udf(col(\"text_with_abbreviations\")))\n",
    "\n",
    "# Alternatively, you can use PySpark's 'when' function for expansion\n",
    "for abbreviation, expansion in abbreviations_map.items():\n",
    "    df_expanded = df_expanded.withColumn(\"expanded_text\", when(col(\"expanded_text\").contains(abbreviation), col(\"expanded_text\").replace(abbreviation, expansion)))\n",
    "\n",
    "# Show the resulting DataFrame\n",
    "df_expanded.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e4bf35fe-af99-4848-9544-2fb5426bb083",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "exchange_rate_pisa_to_inr = 0.4735  # 1 PISA = 0.4735 INR\n",
    "\n",
    "# Convert PISA to INR\n",
    "df_converted = df.withColumn(\"inr_amount\", col(\"pisa_amount\") * lit(exchange_rate_pisa_to_inr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b6c3d902-fe8f-4012-a049-abc42b8dc9e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "\n",
    "\n",
    "# Sample exchange rate data (you should replace this with actual data)\n",
    "exchange_rate_data = [\n",
    "    (\"USD\", \"INR\", 75.0),\n",
    "    # Add more exchange rates as needed\n",
    "]\n",
    "\n",
    "# Create DataFrame for exchange rates\n",
    "exchange_rate_df = spark.createDataFrame(exchange_rate_data, [\"USD\", \"INR\", \"75.0\"])\n",
    "\n",
    "# Sample data with USD amounts\n",
    "usd_data = [\n",
    "    (100,),\n",
    "    (200,),\n",
    "    # Add more data as needed\n",
    "]\n",
    "\n",
    "# Create DataFrame for USD amounts\n",
    "usd_df = spark.createDataFrame(usd_data, [\"usd_amount\"])\n",
    "\n",
    "# Join USD DataFrame with exchange rate DataFrame\n",
    "joined_df = usd_df.crossJoin(exchange_rate_df)\n",
    "\n",
    "# Perform the conversion\n",
    "converted_df = joined_df.withColumn(\"inr_amount\", col(\"usd_amount\") * col(\"rate\"))\n",
    "\n",
    "# Optionally round the converted amount\n",
    "converted_df = converted_df.withColumn(\"inr_amount_rounded\", round(col(\"inr_amount\"), 2))\n",
    "\n",
    "# Select only relevant columns\n",
    "result_df = converted_df.select(\"usd_amount\", \"inr_amount_rounded\")\n",
    "\n",
    "# Show the result\n",
    "result_df.show()\n",
    "\n",
    "# Stop the SparkSession\n",
    "spark.stop()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Mount point Notebook",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}