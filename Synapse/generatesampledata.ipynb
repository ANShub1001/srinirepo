{
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "outputs": [],
      "metadata": {},
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "import random\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "\n",
        "# --- Generate product data ---\n",
        "products = [\n",
        "    (\"P001\", \"Widget A\", \"Electronics\"),\n",
        "    (\"P002\", \"Widget B\", \"Electronics\"),\n",
        "    (\"P003\", \"Chair X\", \"Furniture\"),\n",
        "    (\"P004\", \"Table Z\", \"Furniture\"),\n",
        "    (\"P005\", \"Sofa L\", \"Furniture\"),\n",
        "    (\"P006\", \"Monitor 24\\\"\", \"Electronics\"),\n",
        "    (\"P007\", \"Laptop Pro\", \"Electronics\"),\n",
        "    (\"P008\", \"Desk Comfort\", \"Furniture\"),\n",
        "    (\"P009\", \"Smartwatch G\", \"Electronics\"),\n",
        "    (\"P010\", \"Headphones H\", \"Electronics\")\n",
        "]\n",
        "\n",
        "product_df = spark.createDataFrame(products, [\"product_id\", \"product_name\", \"category\"])\n",
        "product_df.write.mode(\"overwrite\").parquet(\"abfss://demo@srinistracc.dfs.core.windows.net/optdemo/productdata.parquet\")\n",
        "\n",
        "# --- Generate order data ---\n",
        "regions = [\"North\", \"South\", \"East\", \"West\"]\n",
        "order_data = []\n",
        "\n",
        "for i in range(1001, 1056):  # 55 records\n",
        "    order_id = f\"O{i}\"\n",
        "    customer_id = f\"C{random.randint(1, 30):03}\"\n",
        "    product = random.choice(products)[0]\n",
        "    base_date = datetime(2023, 1, 1) + timedelta(days=random.randint(0, 480))  # Between 2023 and 2024\n",
        "    quantity = random.randint(1, 5)\n",
        "    price_per_unit = random.choice([20.0, 25.0, 30.0, 35.0])\n",
        "    total_amount = round(price_per_unit * quantity, 2)\n",
        "    region = random.choice(regions)\n",
        "\n",
        "    order_data.append((order_id, customer_id, product, base_date.date(), quantity, total_amount, region))\n",
        "\n",
        "columns = [\"order_id\", \"customer_id\", \"product_id\", \"order_date\", \"quantity\", \"total_amount\", \"region\"]\n",
        "orders_df = spark.createDataFrame(order_data, columns)\n",
        "\n",
        "orders_df.write.mode(\"overwrite\").parquet(\"abfss://demo@srinistracc.dfs.core.windows.net/optdemo/ordersdata.parquet\")\n",
        ""
      ]
    }
  ],
  "metadata": {
    "description": null,
    "save_output": true,
    "language_info": {
      "name": "python"
    }
  }
}